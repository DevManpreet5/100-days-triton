{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import triton\nimport triton.language as tl\nimport torch\n\n@triton.jit\ndef softmax_kernel(\n    input_ptr, output_ptr,\n    N,\n    BLOCK_SIZE: tl.constexpr\n):\n    input_ptr = input_ptr.to(tl.pointer_type(tl.float32))\n    output_ptr = output_ptr.to(tl.pointer_type(tl.float32))\n    pid = tl.program_id(0)\n    block_start= BLOCK_SIZE * pid\n    offsets= block_start + tl.arange(0, BLOCK_SIZE)\n    mask= offsets < N\n    \n    x = tl.load(input_ptr + offsets, mask=mask,other=float('-inf')) #imp\n    \n    maxv=tl.max(x)\n    x=x-maxv\n    exp_x = tl.exp(x)\n    \n    exp_x = tl.where(mask, exp_x, 0.0) #imp\n    \n    sum_exp = tl.sum(exp_x)\n    softmax = exp_x / sum_exp\n    tl.store(output_ptr + offsets, softmax, mask=mask)\n\ndef solve(input_ptr: int, output_ptr: int, N: int):\n    BLOCK_SIZE = 1024 \n\n    grid_size = triton.cdiv(N, BLOCK_SIZE)\n    \n    softmax_kernel[(grid_size,)](\n        input_ptr, output_ptr,\n        N,\n        BLOCK_SIZE=BLOCK_SIZE\n    )\n\nif __name__ == \"__main__\":\n    input_data = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32, device='cuda')\n    output_data = torch.zeros_like(input_data)\n    \n    solve(input_data.data_ptr(), output_data.data_ptr(), len(input_data))\n    \n    print(input_data)\n    print(output_data)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T16:51:07.587241Z","iopub.execute_input":"2025-06-16T16:51:07.587640Z","iopub.status.idle":"2025-06-16T16:51:07.997708Z","shell.execute_reply.started":"2025-06-16T16:51:07.587621Z","shell.execute_reply":"2025-06-16T16:51:07.996905Z"}},"outputs":[{"name":"stdout","text":"tensor([1., 2., 3.], device='cuda:0')\ntensor([0.0900, 0.2447, 0.6652], device='cuda:0')\n","output_type":"stream"}],"execution_count":2}]}